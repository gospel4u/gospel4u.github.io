title: '운영체제 스터디'
decription: ''
url: 'http://gospel4u.github.io/'
baseurl: ''

author:
  name: 'Hosea Lee'

Basic concepts
Motivation :
Multiprogramming과 multitasking을 사용해서 CPU의 사용량을 최대한으로 늘릴 수 있게 하기 위해서
Resource(CPU 포함)는 process간에 공유된다.
CPU-I/O Burst Cycle
Process가 실행은 CPU execution(CPU burst)과 I/O wait(I/O burst)으로 구성 되어있다.
처음과 마지막은 CPU burst로 이루어져 있다.
Process의 type
I/O bound process : 
짧은 CPU burst로 이루어져 있는 process, I/O burst가 긴 process
즉, I/O를 위주로 실행하는 process
CPU bound process : 
긴 CPU burst로 이루어져 있는 process, I/O burst가 짧은 process
즉, CPU 연산을 위주로 실행하는 process
주의 * CPU bound process는 CPU burst의 빈도수가 많은 것이 아닌 CPU burst의 길이가 긴 것
CPU scheduler
CPU scheduler(= short term scheduler) :
process가 memory에서 CPU로 이동하는 과정을 scheduling 하는 scheduler이다.
우선순위가 높은 process를 찾아 selection 하는 것이 가장 큰 임무이다.
Ready queue는 FIFO, priority queue, tree, unordered linked list로 구현되어 있고 각 process는 PCB로 존재한다.
 Preemptive scheduling
Process가 실행되고 있는 동안에 scheduling이 진행되는 것, CPU에서 process를 실행하고 있는 권한을 잃어버리게 만드는 것
EX) interrupt, process with higher priority
Scheduling이 발생하는 때
Running state → Waiting state <필연적으로 발생 non-preemptive & scheduling >
EX) I/O request, child process가 exit 되기를 기다리기 위해 waiting
Running state → Ready state <필연적으로 발생하지 않음 preemptive & option>
EX) Interrupt 발생(I/O request는 아님)
Waiting state → Ready state <필연적으로 발생하지 않음 preemptive & option>
EX) I/O 종료 시
Running state → Terminated state <필연적으로 발생 non-preemptive & scheduling>
EX) 프로세스 종료 시
Non-preemptive (or Cooperative) scheduling
CPU burst가 끝날 때 까지 지속
1번과 4번(Running → Waiting 과 Running → Terminated)에서 scheduling 진행
Running process는 interrupt 당하지 않는다.
Process가 자발적으로 scheduling 요청
Non-preemptive start point : I/O 시작될 때
Preemptive scheduling
CPU burst가 끝나기 전에 scheduling을 시도하여 중간에 끊음
Scheduling은 1, 2, 3, 4번 모두 일어난다.
Process가 실행 중일 때에도 scheduling이 실행된다.(preemptive)
H/W의 지원이 필요하며 shared data에 접근, 사용하기 위해서 handle이 필요함
Preemptive start point : interrupt handling 직후, system call handling 후
단점 
Race condition이 발생할 가능성이 생긴다.
race condition : 여러 process가 하나의 데이터에 접근하며 생기는 문제
Data가 다수의 process에 의해 공유될 때 문제가 발생(실행 중이던 것을 끊었기 때문에)
운영체제 kernel 설계의 영향을 준다.
EX ) system call을 처리할 동안 kernel은 하나의 process를 위한 activate를 하는데, 이때 다른 process가 선점되면 kernel이 동일한 구조를 읽거나 변경할 필요가 있을 경우에 혼란이 발생한다.(context switching이 일어나지 않은 경우)
-> 대부분의 경우에는 context switching을 수행하기 전에 system call이 완료되거나 I/O request에 따른 차단이 일어나기를 기다리는 방법
장점
Real time process의 responsibility가 좋아진다.
Preemption of OS Kernel
Preemptive kernel은 system call에서 preemption을 허용하는 kernel임
Dispatcher : short-term scheduler에 의해 selection 된 process에 CPU control을 제공하는 module, 실제로 CPU를 process에 할당 시키는 일을 하는 것
Switching context
Switching kernel mode -> user mode
User program에서 적절한 위치로 이동
Dispatcher latency :
하나의 process를 중지하고 다른 process를 시작하기까지 시간
Scheduling 기준
CPU Utilization(CPU 이용률) : 
최대한 CPU가 쉬는 일이 없도록, 최대한 바쁘게 CPU를 활용
Throughput(처리율) : 
단위 시간당 job을 마치는 process가 몇 개인지
Turnaround time(반환시간) : 
CPU time을 요청하고 CPU time이 완성되는 시간 = 실제 실행시간 + waiting time
(작업이 ready queue에 들어가서 나오는 시간의 차이) -> 짧을수록 좋음
Waiting time(대기시간) : 
ready queue에서 기다린 total time 
Response time(응답시간) :
첫 응답이 나올 때 까지 걸리는 시간
각기준의 중요도는 system에 따라서 다르다
Scheduling algorithms
- First-come, first-served (FCFS) scheduling
- Shortest-job-first (SJF) scheduling
- Priority scheduling
- Round-robin scheduling
- Multilevel queue scheduling
- Multiple feedback-queue scheduling

First-come, first-served scheduling (FCFS)


처음으로 CPU를 요청한 process에 CPU를 할당함.
Non-preemptive scheduling
scheduling중에서 가장 simple한 방법
첫 실행 process의 waiting time은 0임
waiting time의 평균이 꽤 길다 -> CPU, I/O utilities가 비효율적 (time unit : msec)
Shortest-Job-First scheduling
<Non-preemptive ver.>

process의 burst time을 적은 순서대로 나열하여 waiting time을 optimize할 수 있다.
단점
- process의 burst time을 알기 어렵다
- > 해결방법 : 이전 history를 기억하여 푸는 방법
Predicting next CPU burst from history
(usually α = 0.5)
정확한 값은 아니지만 측정값과 비슷하게 예측함
<Preemptive ver.>

Burst time이 가장 짧은 것부터 실행하는데, 실행하는 순간마다, update된 burst time을 같이 확인하여 가장 짧은 burst가 생기면 preemptive하게 scheduling을 진행한다.
Process의 도착한 시간이 다르다면, 해당 조건까지 확인하여 burst time을 계산해야 한다.
Priority scheduling
 (priority 숫자가 낮을수록 우선순위 높은 예시)
가장 높은 우선순위를 가진 process에 CPU를 할당한다.
같은 우선순위를 가지고 있다면 FCFS(first-come, first-served) 방식으로 진행한다
Priority는 internally와 externally에 할당할 수 있다.
Internally :
측정가능한 quantity와 qualities에 의해 결정이 된다.
ex) time limit, memory requirement, # of open files, ratio of I/O or CPU burst…
Externally :
중요성, 정책요소에 의해서 결정이 된다. -> 외부에서 user가 설정하는 우선순위
Preemptive scheduling과 Non-preemptive 방식 모두 사용할 수 있다.
Non-preemptive 방식 - 우선순위가 높은 것이 들어오더라도 이전에 들어왔던 process의 우선순위를 먼저 지키는 방식
Preemptive 방식 - 우선순위 높은 것이 들어오게 되면 우선순위 높은 순서로 진행
Priority의 문제점
Indefinite blocking 기한 없는 차단 (= starvation) , 낮은 우선순위를 가지고 있는 process는 계속해서 CPU에 할당이 되지 못하는 상태가 발생하게 됨
해결방법 : aging -> 오랜 시간동안 대기중인 process의 우선순위가 상승하게 되는 방법을 사용한다.
Round-Robin scheduling

FCFS와 비슷하지만, 시간의 제한이 있는 preemptive scheduling으로 진행
Time sharing(시간을 쪼개어 process를 CPU에ㄴ 할당 시키는) system으로 디자인
-> time sharing 기법이 나온 후, 생긴 scheduling이라서
Q. quantum 이 같은 process안에서 반복이 될 경우에 context switching이 일어나나..?
Time quantum(한번씩, 하나의 process에게 주어지는 CPU Time)
CPU time은 time quantum (or time slice)로 나눈다. -> 해당 time이 지나면 강제로 전환

일반적으로 Time quantum은 10~100msec 정도 사용된다.
Circular queue 형태로 갖춰서 돌아가게 만든다.
모든 process는 한번의 quantum의 시간을 가지게 된다.
CPU Time이 time quantum보다 짧으면 그냥 실행하고 다음 schedule을 진행
질문 : P1은 burst time이 많이 남았는데 quantum으로 자르게 된다면 그때마다 context switching이 일어난다는 것인가? -> 그렇다면 overhead가 더 심해지는 것은 아닐까?
Performance of Round-Robin scheduling
Time quantum is small : processor(CPU) sharing이 계속 일어나기 때문에 overhead 발생 가능성이 높아짐
Time quantum is large : FCFS처럼 되기 때문에 Round-Robin scheduling의 기능의 측면이 없어짐
Turnaround time은 time quantum의 크기에 따라서 달라진다.
평균 turnaround time과 time quantum의 크기는 비례하거나 반비례하지 않음
대부분의 process가 다음 CPU burst를 single time quantum으로 처리하게 되면 평균 처리시간이 단축된다. -> 긴 quantum시간은 옳지 않음
해결책 => A rule of thumb : 
약 80%의 cpu burst가 cover되는 크기를 지정하면 turnaround time이 짧아짐.
Multilevel Queue Scheduling

Process를 서로 여러가지 group으로 분류를 하고, 각각에 우선순위가 존재 또한 다른 scheduling을 사용한다.
ex) memory requirement, priority, process type…
Process가 생성되는 순간, group중 하나로 assign 된다.
Assign된 queue에서 기다리고 해당 queue마다 별도의 scheduler algorithm을 사용하며 process 후보를 선택한다.
Group queue간의 경쟁을 어떻게 처리할 것인지 -> queue 간의 scheduling 정책을 정하고 priority가 직접적으로 반영되는 정책
Fixed-priority preemptive scheduling :
이전에 group 우선 순위 정한 것 대로 해당 queue가 process를 제공하지 않을 때까지 우선순위의 queue의 process사용
-> Starvation의 문제점
* Q : os가 scheduling을 하기 때문에 preemptive 라는 성현이 의견
Time-slicing among queue : 
fixed-priority의 문제점을 해결하고자 queue의 우선순위는 존재하되 해당 queue마다의 time slicing을 통해 starvation을 방지함
ex) foreground queue -> interactive processes = 80% CPU time
   background queue -> batch processes(일괄처리 process) = 20% CPU time
   -> 우선순위가 낮은 queue도 CPU time을 가질 수 있게 된다.

Process가 생성될 때, queue에 assign되는데 해당 process는 queue를 이동할 수 없음
Multilevel Feedback-Queue scheduling
Multilevel queue scheduling과 비슷한 scheduling 방식이다. 해당 scheduling과 다른 점은 process가 queue를 옮길 수 있다는 것이다.
Idea : CPU burst의 특성에 따라서 process를 분리하자
Process가 너무 많은 CPU time을 사용하는 경우(CPU bound process)에는 우선순위가 낮은 queue로 이동.
I/O bound process와 interactive process는 우선순위가 높은 queue로 이동.
Multilevel feedback queue scheduler를 만들기 위해 고려해야할 매개변수
Queue의 개수
각 queue의 scheduling algorithm
Process가 service를 제공하려고 할 때, queue를 결정하는 방법
Process의 우선순위를 높이는 시기를 결정하는 방법
Process의 우선순위를 낮추는 시기를 결정하는 방법
굉장히 복잡한 algorithm으로 이루어짐, 거의 모든 OS는 multilevel feedback queue scheduling을 사용함
Multiple-Processor scheduling
Multiple processor system
Processor가 많아지면 load sharing 가능하기에 더 많은 일을 할 수 있게 된다.
Scheduling algorithms이 복잡해지고 문제점이 발생한다.
Multiple processor scheduling에는 많은 방법이 존재하지만 optimizer 해결책은 없다.
해당 text에서는 모든 processor가 동일하며 모든 process를 실행이 가능하다고 가정
Symmetric VS Asymmetric Multiprocessing

Multi - processor scheduling
2개의 strategies 존재 

common ready queue :
Ready queue는 하나로 존재하고, 여러 core들이 하나의 ready queue access
per-core run queues :
각 core마다 ready queue가 하나씩 존재, core 개수 = ready queue 개수
해당 방식을 더 많이 사용함 (process affinity 때문에)
Q. 나누어진 이유가 병렬성 때문인가??
Process Affinity
한 processor에서 다른 processor로 process를 이동하는데 드는 overhead.
processor의 이동을 하게 되면 cache에 있는 내용을 모두 지워야 함.
한 process가 CPU를 바꾸게 되면 성능에 손해를 보게 되어 core0에서 돌아가는 process는 core0에서 돌리고 core1에서 돌아가는 process는 core1에서 돌릴 수 있도록 만드는 것
종류
Soft affinity : 같은 CPU에서 process가 돌아가지만 다른 CPU로 이동은 허용
Hard affinity : 무조건 같은 CPU에서 process가 돌아갈 수 있도록 이동허용X
NUMA(Non-Uniform Memory Access) & CPU Scheduling
각 CPU마다 memory가 정해져 있고, 정해진 memory 외 공간에 접근하면 속도의 성능이 느려 진다. → Affinity를 철저하게 지키는 것이 좋음
Load Balancing
Processor-1 에는 일이 많은데 나머지 processor-2~processor-4는 일이 존재하지 않음 일이 많은 processor-1의 일을 나머지 processor에게 분배해야 한다.
Workload(task 양)가 골고루 processor에게 분산될 수 있도록 시도하는 기술
→ 각 processor 마다 본인의 ready queue가 존재해야 한다.
방법
Push Migration : 
각각의 processor load를 주기적으로 확인 하는 방식 
<load가 많은 쪽 → load가 적은 쪽> process를 이동
Pull Migration : 
현재 processor의 일이 사라지는 순간, 다른 processor의 일을 가지고 오는 방식
Push와 Pull Migration이 충돌되는 방식이 아니라, 같이 사용되는 경우가 많음
Process Affinity은 Migration을 막는 정책 
Load Balancing은 Migration을 장려 정책
CPU가 놀고있는 것보다 Migration을 시도하여 여러 CPU 사용하는 것이 나음
Multi-core Processors
Chip에 여러 개의 processor core가 존재함
→ 각 system이 사용하는 
Memory Stall (문제점) : Process가 명령을 실행할 때, memory에서 읽고 쓰고 한다. Memory의 성능이 좋지 않다면 memory access하는 순간, 기다리는 시간이 생기게 된다.
→ CPU가 빠르더라도 Memory가 느려서 속도가 저하되는 상황이 발생
Multithreaded processor cores (해결) : 

CPU가 memory를 access할 때, CPU는 남의 thread를 더 실행하는 방법
→ 하나의 core에 여러 개의 2배 이상의 thread가 할당되어 돌아간다.
Thread scheduling
Thread scheduling
User thread : thread library에 의해 지원됨
Kernel thread : OS kernel에 의해 지원됨 
실제로 OS에서 scheduling 하는 것은 process가 아닌, kernel thread 이다.

Contention scope (경쟁의 범위) 
Process-contention scope (PCS) 
User thread간 LWP 경쟁 (Many-to-one model or Many-to-many model)
Priority를 기준으로 경쟁
System-contention scope (SCS)
Kernel thread간 CPU 경쟁 (One-to-one model)

Thread scheduling
PCS(PTHREAD_SCOPE_PROCESS) → user thread
ex) many-to-one model / one-to-many
SCS(PTHREAD_SCOPE_SYSTEM) → kernel thread
ex) one-to-one model
Function
pthread_attr_setscope(pthread_attr_t *attr, int scope)
- thread가 어떠한 scope에서 작동하게 할 것인지 결정하기 위해서 사용
- attr에 scope를 직접 넣어줄 때 사용하는 function
ex) pthread_attr_setscope(&attr, PTHREAD_SCOPE_PROCESS) 
→ use user thread
pthread_attr_getscope(pthread_attr_t *attr, int scope)
- scope의 값을 빼서, attr에 넣기 PCS와 SCS 중 하나 제공
- thread가 어떤 scope에서 다루어 지고 있는지 얻어 오기 위해서 사용된다. 
ex) pthread_attr_getscope(&attr, &scope)
int scope / attribute는 무조건 pthread_attr_init()으로 초기화 시켜줘야 함
Real-time CPU scheduling
Real-time CPU Scheduling
Real-time Operating System(RTOS)
Real time system을 만들기 위해 제공해주는 OS
real time : 정해진 시간안에 수행되는 system
Ex) 로봇존재 → 절벽인지 벽이 있는지 감지 센서 존재 → 느리게 반응 → 벽에 부딪힘 : 문제점이 존재 함 → 정해진 시간 한도 안에 답이 나와야 하는 해결이 필요함
몇 msec에 답을 제공 요청 → 시간안에 답을 줄 수 있으면 : 해결
몇 msec에 답을 제공 요청 → 시간안에 답을 줄 수 없으면 : false return (다시 물어봄)
Soft real-time systems 
Real-time type의 process가 존재하게 되면 우선순위를 최고로 올리는 system
의미 : real-time process는 빨리 실행되어야 하는 process이기 때문에 우선순위를 높여서 real-time process가 빨리 돌 수 있도록 만드는 방법
Ex) Linux
Hard real-time system (진정한 의미의 real-time)
운영체제의 system call이 들어왔을 경우에 제한시간을 제공, 운영체제가 시간안에 해결 or 시간안에 해결 못하면 false return 
개발자들이 개발하기 어려워하는 system
Real-time system을 만들기 위한 part
OS part : 요청이 온 request에 대해서 보장
Application part : 운영체제가 control 할 수 없음
Minimizing Latency
Real time system이 가져야하는 조건 = latency(대기)가 짧아야 한다. 
System call이 요청  → 무조건 빨리 반응과 답을 주어야함
대부분 real time system은 Event-Driven system(EDS)로 이루어져 있다.
Event latency :
event가 발생 후 system이 응답하기까지 시간 (interrupt latency + dispatch latency)
Interrupt latency : 
event는 interrupt의 형태로 발생, 어떤 handler를 호출 판단하는 latency. 
Interrupt → determine interrupt type :
어떤 interrupt가 발생할지, 어떤 interrupt handler routine 실행될지 결정
Context switch :
CPU에서 실행중인 process의 정보를 PCB에 저장여 ISR이 실행될 수 있도록 만들어준다.
Q. dispatcher latency에 context switch가 포함인가? 
dispatcher latency :
interrupt에 의해 context switching을 거치고 다시 준비상태로 되돌아온 process가 존재한다면 해당 프로세스를 block 시키고 우선 순위가 높은 다른 프로세스를 시작시키는 데에 걸리는 시간

preemptive kernel을 사용 함 
이전에 실행되고 있던 system call을 멈추고 real-time으로 발생한 event를 바로 실행가능하기에 dispatch latency를 짧게 유지할 수 있다.
Conflict phase 
Preemption 방식으로 기존의 process가 CPU에서 돌고있으면 process를 block 시키는 것
Real time request보다 낮은 priority를 가진 process가 request가 필요한 resource를 사용하고 있을 때 high priority를 가진 process에게 resource 전달.
총정리 : 
dispatch latency에 영향을 주는 것 = Conflict 
첫번째로 커널에서 수행중인 작업이 있어 preemptive할 수 없는 경우 존재. Non-preemptive kernel을 사용할 시 그런 경우가 많아 진다. 이러한 경우는 preemptive 커널의 사용으로 최소화가 가능하다. 
두번째 충돌 요소로는 높은 우선순위의 process가 필요로 하는 resource를 낮은 우선순위의 process가 선점하고 있는 경우이다. 이럴 경우 낮은 우선순위의 process가 해당 resource를 release할 때까지 기다려야 한다.
